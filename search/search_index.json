{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AWS Observability Accelerator for CDK","text":"<p>Welcome to the AWS Observability Accelerator for CDK!</p> <p>The AWS Observability Accelerator for CDK is a set of opinionated modules to help you set up observability for your AWS environments with AWS Native services and AWS-managed observability services such as Amazon Managed Service for Prometheus,Amazon Managed Grafana, AWS Distro for OpenTelemetry (ADOT) and Amazon CloudWatch.</p> <p>We provide curated metrics, logs, traces collection, cloudwatch dashboard, alerting rules and Grafana dashboards for your EKS infrastructure, Java/JMX, NGINX based workloads and your custom applications.</p>"},{"location":"#single-eks-cluster-aws-native-observability-accelerator","title":"Single EKS Cluster AWS Native Observability Accelerator","text":""},{"location":"#single-eks-cluster-open-source-observability-accelerator","title":"Single EKS Cluster Open Source Observability Accelerator","text":""},{"location":"#patterns","title":"Patterns","text":"<p>The individual patterns can be found in the <code>lib</code> directory.  Most of the patterns are self-explanatory, for some more complex examples please use this guide and docs/patterns directory for more information.</p>"},{"location":"#usage","title":"Usage","text":"<p>Before proceeding, make sure AWS CLI is installed on your machine.</p> <p>To use the eks-blueprints and patterns module, you must have Node.js and npm installed. You will also use <code>make</code> and <code>brew</code> to simplify build and other common actions. </p>"},{"location":"#ubuntu-setup","title":"Ubuntu Setup","text":"<p>Follow the below steps to setup and leverage cdk-aws-observability-accelerator in your Ubuntu Linux machine.</p> <ol> <li> <p>Update the package list </p> <p>Update the package list to ensure you're installing the latest versions.</p> <pre><code>sudo apt update\n</code></pre> </li> <li> <p>Install make</p> <pre><code>sudo apt install make\n</code></pre> </li> <li> <p>Install Node.js and npm</p> <p>Install Node.js and npm using the NodeSource binary distributions. <pre><code>curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - &amp;&amp;\\\nsudo apt-get install -y nodejs\n</code></pre></p> <p>Note: The Node.js package from NodeSource includes npm</p> </li> <li> <p>Verify Node.js and npm Installation</p> <p>Check the installed version of Node.js:</p> <pre><code>node -v\n</code></pre> <p>The output should be <code>v20.x.x</code>.</p> <p>Check the installed version of npm:</p> <pre><code>npm -v\n</code></pre> <p>The output should be a version greater than <code>9.7.x</code>.</p> <p>If your npm version is not <code>9.7.x</code> or above, update npm with the following command:</p> <pre><code>sudo npm install -g npm@latest\n</code></pre> <p>Verify the installed version by running <code>npm -v</code>.</p> </li> <li> <p>Install brew on ubuntu by following instructions as detailed in docs.brew.sh <pre><code> /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre>    Add Homebrew to your PATH    <pre><code>test -d ~/.linuxbrew &amp;&amp; eval \"$(~/.linuxbrew/bin/brew shellenv)\"\ntest -d /home/linuxbrew/.linuxbrew &amp;&amp; eval \"$(/home/linuxbrew/.linux  brew/bin/brew shellenv)\"\ntest -r ~/.bash_profile &amp;&amp; echo \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.bash_profile\necho \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.profile\n</code></pre></p> </li> </ol> <p>Post completing the above, continue from Step: Repo setup</p>"},{"location":"#mac-setup","title":"Mac Setup:","text":"<p>Follow the below steps to setup and leverage <code>cdk-aws-observability-accelerator</code> in your local Mac laptop.</p> <ol> <li>Install <code>make</code> and <code>node</code> using brew</li> </ol> <pre><code>brew install make\nbrew install node\n</code></pre> <ol> <li>Install <code>npm</code></li> </ol> <pre><code>sudo npm install -g n\nsudo n stable\n</code></pre> <ol> <li> <p>Make sure the following pre-requisites are met:</p> </li> <li> <p>Node version is a current stable node version 18.x.</p> </li> </ol> <pre><code>$ node -v\nv20.3.1\n</code></pre> <p>Update (provided Node version manager is installed): <code>n stable</code>. May require <code>sudo</code>.</p> <ul> <li>NPM version must be 8.4 or above:</li> </ul> <pre><code>$ npm -v\n9.7.2\n</code></pre> <p>Updating npm: <code>sudo n stable</code> where stable can also be a specific version above 8.4. May require <code>sudo</code>.</p>"},{"location":"#repo-setup","title":"Repo setup","text":"<ol> <li>Clone the <code>cdk-aws-observability-accelerator</code> repository</li> </ol> <pre><code>git clone https://github.com/aws-observability/cdk-aws-observability-accelerator.git\n</code></pre> <p>PS: If you are contributing to this repo, please make sure to fork the repo, add your changes and create a PR against it.</p> <ol> <li> <p>Once you have cloned the repo, you can open it using your favourite IDE and run the below commands to install the dependencies and build the existing patterns.</p> </li> <li> <p>Install project dependencies.</p> </li> </ol> <pre><code>make deps\n</code></pre> <ul> <li>To view patterns that are available to be deployed, execute the following:</li> </ul> <pre><code>make build\n</code></pre> <ul> <li>To list the existing CDK AWS Observability Accelerator Patterns</li> </ul> <pre><code>make list\n</code></pre> <p>Note: Some patterns have a hard dependency on AWS Secrets (for example GitHub access tokens). Initially you will see errors complaining about lack of the required secrets. It is normal. At the bottom, it will show the list of patterns which can be deployed, in case the pattern you are looking for is not available, it is due to the hard dependency which can be fixed by following the docs specific to those patterns.</p> <pre><code>To work with patterns use:\n    $ make pattern &lt;pattern-name&gt; &lt;list | deploy | synth | destroy&gt;\nExample:\n    $ make pattern single-new-eks-opensource-observability deploy\n\nPatterns:\n\n    existing-eks-mixed-observability\n    existing-eks-opensource-observability\n    single-new-eks-awsnative-observability\n    single-new-eks-cluster\n    single-new-eks-graviton-opensource-observability\n    single-new-eks-mixed-observability\n    single-new-eks-opensource-observability\n</code></pre> <ul> <li>Bootstrap your CDK environment.</li> </ul> <pre><code>npx cdk bootstrap\n</code></pre> <ul> <li>You can then deploy a specific pattern with the following:</li> </ul> <pre><code>make pattern single-new-eks-opensource-observability deploy\n</code></pre>"},{"location":"#developer-flow","title":"Developer Flow","text":""},{"location":"#modifications","title":"Modifications","text":"<p>All files are compiled to the dist folder including <code>lib</code> and <code>bin</code> directories. For iterative development (e.g. if you make a change to any of the patterns) make sure to run compile:</p> <pre><code>make compile\n</code></pre> <p>The <code>compile</code> command is optimized to build only modified files and is fast. </p>"},{"location":"#new-patterns","title":"New Patterns","text":"<p>To create a new pattern, please follow these steps:</p> <ol> <li>Under lib create a folder for your pattern, such as <code>&lt;pattern-name&gt;-construct</code>. If you plan to create a set of patterns that represent a particular subdomain, e.g. <code>security</code> or <code>hardening</code>, please create an issue to discuss it first. If approved, you will be able to create a folder with your subdomain name and group your pattern constructs under it. </li> <li>Blueprints generally don't require a specific class, however we use a convention of wrapping each pattern in a plain class like <code>&lt;Pattern-Name&gt;Construct</code>. This class is generally placed in <code>index.ts</code> under your pattern folder. </li> <li>Once the pattern implementation is ready, you need to include it in the list of the patterns by creating a file <code>bin/&lt;pattern-name&gt;.ts</code>. The implementation of this file is very light, and it is done to allow patterns to run independently.</li> </ol> <p>Example simple synchronous pattern: <pre><code>import SingleNewEksOpenSourceobservabilityConstruct from '../lib/single-new-eks-opensource-observability-construct';\nimport { configureApp } from '../lib/common/construct-utils';\n\nconst app = configureApp();\n\nnew SingleNewEksOpenSourceobservabilityConstruct(app, 'single-new-eks-opensource');\n// configureApp() will create app and configure loggers and perform other prep steps\n</code></pre></p>"},{"location":"#security","title":"Security","text":"<p>See CONTRIBUTING for more information.</p>"},{"location":"#license","title":"License","text":"<p>This library is licensed under the MIT-0 License. See the LICENSE file.</p>"},{"location":"contributors/","title":"Contributors","text":"<p>The content on this site is maintained by the Solutions Architects from the AWS observability team with support from the AWS service teams and other volunteers from across the organization.</p> <p>Our goal is to make it easier to use AWS Native and Open Source Observability Services.</p> <p>The core team include the following people:</p> <ul> <li>Elamaran Shanmugam</li> <li>Imaya Kumar Jagannathan</li> <li>Kevin Lewin</li> <li>Michael Hausenblas</li> <li>Mikhail Shapirov</li> <li>Rodrigue Koffi</li> </ul> <p>We welcome the wider open source community and thank those who contribute to this project.</p> <p>Note that all information published on this site is available via the Apache 2.0 license.</p>"},{"location":"support/","title":"Support &amp; Feedback","text":"<p>AWS Observability Accelerator for CDK is maintained by AWS Solution Architects. It is not part of an AWS service and support is provided best-effort by the AWS Observability Accelerator community.</p> <p>To post feedback, submit feature ideas, or report bugs, please use the issues section of this GitHub repo.</p> <p>If you are interested in contributing, see the contribution guide.</p>"},{"location":"tracing/","title":"Tracing on Amazon EKS","text":"<p>Distributed tracing helps you have end-to-end visibility between transactions in distributed nodes. The <code>eks-monitoring</code> module is configured  by default to collect traces into AWS X-Ray.</p> <p>The AWS Distro for OpenTelemetry collector is configured to receive traces in the OTLP format (OTLP receiver), using the OpenTelemetry SDK or auto-instrumentation agents.</p> <p>Note</p> <p>To disable the tracing configuration, <code>XrayAdotAddOn</code> for Mixed and Open Source Observability Accelerators from the CDK Observability Patterns</p>"},{"location":"tracing/#instrumentation","title":"Instrumentation","text":"<p>Let's take a sample application that is already instrumented with the OpenTelemetry SDK.</p> <p>Note</p> <p>To learn more about instrumenting with OpenTelemetry, please visit the OpenTelemetry documentation for your programming language.</p> <p>Cloning the repo</p> <pre><code>git clone https://github.com/aws-observability/aws-otel-community.git\ncd aws-otel-community/sample-apps/go-sample-app\n</code></pre> <p>Highlighting code sections</p>"},{"location":"tracing/#deploying-on-amazon-eks","title":"Deploying on Amazon EKS","text":"<p>Using the sample application, we will build a container image, create and push an image on Amazon ECR. We will use a Kubernetes manifest to deploy to an EKS cluster.</p> <p>Warning</p> <p>The following steps require that you have an EKS cluster ready. To deploy an EKS cluster, please visit our example.</p>"},{"location":"tracing/#building-container-image","title":"Building container image","text":"amd64 linuxcross platform build <pre><code>docker build -t go-sample-app .\n</code></pre> <pre><code>docker buildx build -t go-sample-app . --platform=linux/amd64\n</code></pre>"},{"location":"tracing/#publishing-on-amazon-ecr","title":"Publishing on Amazon ECR","text":"using docker <pre><code>export ECR_REPOSITORY_URI=$(aws ecr create-repository --repository go-sample-app --query repository.repositoryUri --output text)\naws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REPOSITORY_URI\ndocker tag go-sample-app:latest \"${ECR_REPOSITORY_URI}:latest\"\ndocker push \"${ECR_REPOSITORY_URI}:latest\"\n</code></pre>"},{"location":"tracing/#deploying-on-amazon-eks_1","title":"Deploying on Amazon EKS","text":"eks.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: go-sample-app\nnamespace: default\nspec:\nreplicas: 2\nselector:\nmatchLabels:\napp: go-sample-app\ntemplate:\nmetadata:\nlabels:\napp: go-sample-app\nspec:\ncontainers:\n- name: go-sample-app\nimage: \"${ECR_REPOSITORY_URI}:latest\" # make sure to replace this variable\nimagePullPolicy: Always\nenv:\n- name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT\nvalue: adot-collector.adot-collector-kubeprometheus.svc.cluster.local:4317\nresources:\nlimits:\ncpu:  300m\nmemory: 300Mi\nrequests:\ncpu: 100m\nmemory: 180Mi\nports:\n- containerPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: go-sample-app\nnamespace: default\nlabels:\napp: go-sample-app\nspec:\nports:\n- protocol: TCP\nport: 8080\ntargetPort: 8080\nselector:\napp: go-sample-app\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: go-sample-app\nnamespace: default\nspec:\ntype: ClusterIP\nselector:\napp: go-sample-app\nports:\n- protocol: TCP\nport: 8080\ntargetPort: 8080\n</code></pre>"},{"location":"tracing/#deploying-and-testing","title":"Deploying and testing","text":"<p>With the Kubernetes manifest ready, run:</p> <pre><code>kubectl apply -f eks.yaml\n</code></pre> <p>You should see the pods running with the command:</p> <pre><code>kubectl get pods\nNAME                              READY   STATUS    RESTARTS        AGE\ngo-sample-app-67c48ff8c6-bdw74    1/1     Running   0               4s\ngo-sample-app-67c48ff8c6-t6k2j    1/1     Running   0               4s\n</code></pre> <p>To simulate some traffic you can forward the service port to your local host and test a few queries</p> <pre><code>kubectl port-forward deployment/go-sample-app 8080:8080\n</code></pre> <p>Test a few endpoints</p> <pre><code>curl http://localhost:8080/\ncurl http://localhost:8080/outgoing-http-call\ncurl http://localhost:8080/aws-sdk-call\ncurl http://localhost:8080/outgoing-sampleapp\n</code></pre>"},{"location":"tracing/#visualizing-traces","title":"Visualizing traces","text":"<p>As this is a basic example, the service map doesn't have a lot of nodes, but this shows you how to setup tracing in your application and deploying it on Amazon EKS using our OSS observability patterns.</p> <p>With Flux and Grafana Operator, the OSS pattern configures an AWS X-Ray data source on your provided Grafana workspace. Open the Grafana explorer view and select the X-Ray data source. If you type the query below, and select <code>Trace List</code> for Query Type, you should see the list of traces occured in the selected timeframe.</p> <p></p> <p>You can add the service map to a dashbaord, for example a service focused dashbaord. You can click on any of the traces to view a node map and the traces details.</p> <p>There is a button that can take you the CloudWatch console to view the same data. If your logs are stored on CloudWatch Logs, this page can present all the logs in the trace details page. The CloudWatch Log Group name should be added to the trace as an attribute. Read more about this in our One Observability Workshop</p> <p></p>"},{"location":"tracing/#resoures","title":"Resoures","text":"<ul> <li>AWS Observability Best Practices</li> <li>One Observability Workshop</li> <li>AWS Distro for OpenTelemetry documentation</li> <li>AWS X-Ray user guide</li> <li>OpenTelemetry documentation</li> </ul>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/","title":"Existing EKS Cluster AWS Native Observability Accelerator","text":""},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/#architecture","title":"Architecture","text":"<p>The following figure illustrates the architecture of the pattern we will be deploying for Existing EKS Cluster AWS Native Observability pattern, using AWS native tools such as CloudWatch and Logs and Open Source tools such as Amazon Distro for OpenTelmetry (ADOT).</p> <p>[!NOTE] Currently, Xray AddOn is not supported for imported clusters. The Xray AddOn requires access to the nodegroup which is not available with the imported cluster and it does not support IRSA as of now and requires modification of the node instance role. Once it supports IRSA, we would update this pattern to work with the existing clusters.</p> <p></p> <p>This example makes use of CloudWatch, as a metric and log aggregation layer. In order to collect the metrics and traces, we use the Open Source ADOT collector. Fluent Bit is used to export the logs to CloudWatch Logs.</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/#objective","title":"Objective","text":"<p>This pattern aims to add Observability on top of an existing EKS cluster, with AWS services.</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/#prerequisites","title":"Prerequisites:","text":"<p>Ensure that you have installed the following tools on your machine:</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol> <p>You will also need:</p> <ol> <li>Either an existing EKS cluster, or you can setup a new one with  Single New EKS Cluster Observability Accelerator</li> <li>An OpenID Connect (OIDC) provider, associated to the above EKS cluster (Note: Single EKS Cluster Pattern takes care of that for you)</li> </ol>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/#deploying","title":"Deploying","text":"<ol> <li>Edit <code>~/.cdk.json</code> by setting the name of your existing cluster:</li> </ol> <pre><code>    \"context\": {\n...\n\"existing.cluster.name\": \"...\",\n...\n}\n</code></pre> <ol> <li>Edit <code>~/.cdk.json</code> by setting the kubectl role name; if you used Single New EKS Cluster Observability Accelerator to setup your cluster, the kubectl role name would be provided by the output of the deployment, on your command-line interface (CLI):</li> </ol> <pre><code>    \"context\": {\n...\n\"existing.kubectl.rolename\":\"...\",\n...\n}\n</code></pre> <ol> <li>Run the following command from the root of this repository to deploy the pipeline stack:</li> </ol> <pre><code>make build\nmake pattern existing-eks-awsnative-observability-construct deploy\n</code></pre>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/#verify-the-resources","title":"Verify the resources","text":"<p>Run update-kubeconfig command. You should be able to get the command from CDK output message. <pre><code>aws eks update-kubeconfig --name single-new-eks-observability-accelerator --region &lt;your-region&gt; --role-arn arn:aws:iam::**************:role/single-new-eks-observabil-singleneweksobservabilit-CPAN247ASDF\n</code></pre> Let\u2019s verify the resources created by steps above.</p> <pre><code>kubectl get nodes -o wide\n</code></pre> <p>Output: <pre><code>NAME                           STATUS   ROLES    AGE   VERSION\nip-10-0-145-216.ec2.internal   Ready    &lt;none&gt;   14m   v1.25.11-eks-a5565ad\n</code></pre></p> <p>Next, lets verify the namespaces in the cluster: <pre><code>kubectl get ns # Output shows all namespace\n</code></pre></p> <p>Output: <pre><code>NAME                       STATUS   AGE\namazon-metrics             Active   4m31s\naws-for-fluent-bit         Active   4m31s\ncert-manager               Active   4m31s\ndefault                    Active   24m\nkube-node-lease            Active   24m\nkube-public                Active   24m\nkube-system                Active   24m\nprometheus-node-exporter   Active   13m\n</code></pre></p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/#visualization","title":"Visualization","text":"<ul> <li>Navigate to CloudWatch &gt; Insights &gt; Container Insights and select cluster, select <code>single-new-eks-cluster</code> if you created cluster with pattern mentioned from above guide, otherwise select relevant cluster.</li> <li>Now select <code>amazon-metrics</code> namepsace </li> <li> <p>On a same view, select 'EKS Pods', which provides insights overview of all the pods as shown below </p> </li> <li> <p>Please see Single New EKS Cluster AWS Mixed Observability Accelerator for Logs.</p> </li> </ul>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-awsnative-observability/#teardown","title":"Teardown","text":"<p>You can teardown the whole CDK stack with the following command:</p> <pre><code>make pattern existing-eks-awsnative-observability-construct destroy\n</code></pre> <p>If you setup your cluster with Single New EKS Cluster Observability Accelerator, you also need to run:</p> <pre><code>make pattern single-new-eks-cluster destroy\n</code></pre>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-mixed-observability/","title":"Existing EKS Cluster AWS Mixed Observability Accelerator","text":""},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-mixed-observability/#architecture","title":"Architecture","text":"<p>The following figure illustrates the architecture of the pattern we will be deploying for Existing EKS Cluster AWS Mixed Observability pattern, using AWS native tools such as CloudWatch and X-Ray and Open Source tools such as Amazon Distro for OpenTelmetry (ADOT) and Prometheus Node Exporter.</p> <p></p> <p>This example makes use of CloudWatch, as a metric and log aggregation layer, while X-Ray is used as a trace-aggregation layer. In order to collect the metrics and traces, we use the Open Source ADOT collector. Fluent Bit is used to export the logs to CloudWatch Logs.</p> <p>In this architecture, AWS X-Ray provides a complete view of requests as they travel through your application and filters visual data across payloads, functions, traces, services, and APIs. X-Ray also allows you to perform analytics, to gain powerful insights about your distributed trace data.</p> <p>Utilizing CloudWatch and X-Ray as an aggregation layer allows for a fully-managed scalable telemetry backend. In this example we get those benefits while still having the flexibility and rapid development of the Open Source collection tools.</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-mixed-observability/#objective","title":"Objective","text":"<p>This pattern aims to add Observability on top of an existing EKS cluster, with a mixture of AWS native and open source managed AWS services.</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-mixed-observability/#prerequisites","title":"Prerequisites:","text":"<p>Ensure that you have installed the following tools on your machine:</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol> <p>You will also need:</p> <ol> <li>Either an existing EKS cluster, or you can setup a new one with  Single New EKS Cluster Observability Accelerator</li> <li>An OpenID Connect (OIDC) provider, associated to the above EKS cluster (Note: Single EKS Cluster Pattern takes care of that for you)</li> </ol>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-mixed-observability/#deploying","title":"Deploying","text":"<ol> <li>Edit <code>~/.cdk.json</code> by setting the name of your existing cluster:</li> </ol> <pre><code>    \"context\": {\n...\n\"existing.cluster.name\": \"...\",\n...\n}\n</code></pre> <ol> <li>Edit <code>~/.cdk.json</code> by setting the kubectl role name; if you used Single New EKS Cluster Observability Accelerator to setup your cluster, the kubectl role name would be provided by the output of the deployment, on your command-line interface (CLI):</li> </ol> <pre><code>    \"context\": {\n...\n\"existing.kubectl.rolename\":\"...\",\n...\n}\n</code></pre> <ol> <li>Run the following command from the root of this repository to deploy the pipeline stack:</li> </ol> <pre><code>make build\nmake pattern existing-eks-mixed-observability deploy\n</code></pre>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-mixed-observability/#verify-the-resources","title":"Verify the resources","text":"<p>Please see Single New EKS Cluster AWS Mixed Observability Accelerator.</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-mixed-observability/#teardown","title":"Teardown","text":"<p>You can teardown the whole CDK stack with the following command:</p> <pre><code>make pattern existing-eks-mixed-observability destroy\n</code></pre> <p>If you setup your cluster with Single New EKS Cluster Observability Accelerator, you also need to run:</p> <pre><code>make pattern single-new-eks-cluster destroy\n</code></pre>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-opensource-observability/","title":"Existing EKS Cluster Open Source Observability Accelerator","text":""},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-opensource-observability/#architecture","title":"Architecture","text":"<p>The following figure illustrates the architecture of the pattern we will be deploying for Existing EKS Cluster Open Source Observability pattern, using AWS native tools such as CloudWatch, AWS Managed Prometheus(AMP), AWS Managed Grafana(AMG), and X-Ray and Open Source tools such as Amazon Distro for OpenTelmetry (ADOT) and Prometheus Node Exporter.</p> <p></p> <p>Monitoring Amazon Elastic Kubernetes Service (Amazon EKS) for metrics has two categories: the control plane and the Amazon EKS nodes (with Kubernetes objects). The Amazon EKS control plane consists of control plane nodes that run the Kubernetes software, such as etcd and the Kubernetes API server. To read more on the components of an Amazon EKS cluster, please read the service documentation.</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-opensource-observability/#objective","title":"Objective","text":"<p>Configure the existing Amazon EKS cluster with below Observability components; - AWS Distro For OpenTelemetry Operator and Collector for Metrics and Traces - Logs with AWS for FluentBit - Installs Grafana Operator to add AWS data sources and create Grafana Dashboards to Amazon Managed Grafana. - Installs FluxCD to perform GitOps sync of a Git Repo to EKS Cluster. We will use this later for creating Grafana Dashboards and AWS datasources to Amazon Managed Grafana. You can also use your own GitRepo  to sync your own Grafana resources such as Dashboards, Datasources etc. Please check our One observability module - GitOps with Amazon Managed Grafana to learn more about this. - Installs External Secrets Operator to retrieve and Sync the Grafana API keys. - Amazon Managed Grafana Dashboard and data source - Alerts and recording rules with AWS Managed Service for Prometheus</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-opensource-observability/#prerequisites","title":"Prerequisites:","text":"<p>Ensure that you have installed the following tools on your machine:</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol> <p>You will also need:</p> <ol> <li>Either an existing EKS cluster, or you can setup a new one with  Single New EKS Cluster Observability Accelerator</li> <li>An OpenID Connect (OIDC) provider, associated to the above EKS cluster (Note: Single EKS Cluster Pattern takes care of that for you)</li> </ol>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-opensource-observability/#deploying","title":"Deploying","text":"<ol> <li>Edit <code>~/.cdk.json</code> by setting the name of your existing cluster:</li> </ol> <pre><code>    \"context\": {\n...\n\"existing.cluster.name\": \"...\",\n...\n}\n</code></pre> <ol> <li>Edit <code>~/.cdk.json</code> by setting the kubectl role name; if you used Single New EKS Cluster Observability Accelerator to setup your cluster, the kubectl role name would be provided by the output of the deployment, on your command-line interface (CLI):</li> </ol> <pre><code>    \"context\": {\n...\n\"existing.kubectl.rolename\":\"...\",\n...\n}\n</code></pre> <ol> <li>Amazon Managed Grafana workspace: To visualize metrics collected, you need an Amazon Managed Grafana workspace. If you have an existing workspace, create an environment variable as described below. To create a new workspace, visit our supporting example for Grafana</li> </ol> <p>Note</p> <p>For the URL <code>https://g-xyz.grafana-workspace.us-east-1.amazonaws.com</code>, the workspace ID would be <code>g-xyz</code></p> <pre><code>export AWS_REGION=&lt;YOUR AWS REGION&gt;\nexport COA_AMG_WORKSPACE_ID=g-xxx\nexport COA_AMG_ENDPOINT_URL=https://g-xyz.grafana-workspace.us-east-1.amazonaws.com\n</code></pre> <p>Warning</p> <p>Setting up environment variables <code>COA_AMG_ENDPOINT_URL</code> and <code>AWS_REGION</code> is mandatory for successful execution of this pattern.</p> <ol> <li>GRAFANA API KEY: Amazon Managed Grafana provides a control plane API for generating Grafana API keys.</li> </ol> <pre><code>export AMG_API_KEY=$(aws grafana create-workspace-api-key \\\n--key-name \"grafana-operator-key\" \\\n--key-role \"ADMIN\" \\\n--seconds-to-live 432000 \\\n--workspace-id $COA_AMG_WORKSPACE_ID \\\n--query key \\\n--output text)\n</code></pre> <ol> <li>AWS SSM Parameter Store for GRAFANA API KEY: Update the Grafana API key secret in AWS SSM Parameter Store using the above new Grafana API key. This will be referenced by Grafana Operator deployment of our solution to access Amazon Managed Grafana from Amazon EKS Cluster</li> </ol> <pre><code>aws ssm put-parameter --name \"/cdk-accelerator/grafana-api-key\" \\\n--type \"SecureString\" \\\n--value $AMG_API_KEY \\\n--region $AWS_REGION\n</code></pre> <ol> <li> <p>Install project dependencies by running <code>npm install</code> in the main folder of this cloned repository.</p> </li> <li> <p>The actual settings for dashboard urls are expected to be specified in the CDK context. Generically it is inside the cdk.json file of the current directory or in <code>~/.cdk.json</code> in your home directory.</p> </li> </ol> <p>Example settings: Update the context in <code>cdk.json</code> file located in <code>cdk-eks-blueprints-patterns</code> directory</p> <pre><code>    \"context\": {\n        \"cluster.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/cluster.json\",\n        \"kubelet.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/kubelet.json\",\n        \"namespaceworkloads.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/namespace-workloads.json\",\n        \"nodeexporter.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/nodeexporter-nodes.json\",\n        \"nodes.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/nodes.json\",\n        \"workloads.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/workloads.json\",\n        \"apiserver.basic.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-basic.json\",\n        \"apiserver.advanced.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-advanced.json\",\n        \"apiserver.troubleshooting.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-troubleshooting.json\",\n      }\n</code></pre> <ol> <li>Once all pre-requisites are set you are ready to deploy the pipeline. Run the following command from the root of this repository to deploy the pipeline stack:</li> </ol> <pre><code>make build\nmake pattern existing-eks-opensource-observability deploy\n</code></pre>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-opensource-observability/#verify-the-resources","title":"Verify the resources","text":"<p>Please see Single New EKS Open Source Observability Accelerator.</p>"},{"location":"patterns/existing-eks-observability-accelerators/existing-eks-opensource-observability/#teardown","title":"Teardown","text":"<p>You can teardown the whole CDK stack with the following command:</p> <pre><code>make pattern existing-eks-opensource-observability destroy\n</code></pre> <p>If you setup your cluster with Single New EKS Cluster Observability Accelerator, you also need to run:</p> <pre><code>make pattern single-new-eks-cluster destroy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/","title":"Single New EKS Cluster AWS Native Observability Accelerator","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#architecture","title":"Architecture","text":"<p>The following figure illustrates the architecture of the pattern we will be deploying for Single EKS Cluster Native Observability pattern using AWS native tools such as CloudWatch Logs and Container Insights.</p> <p></p> <p>This example makes use of CloudWatch Container Insights as a vizualization and metric-aggregation layer. Amazon CloudWatch Container Insights helps customers collect, aggregate, and summarize metrics and logs from containerized applications and microservices. Metrics data is collected as performance log events using the embedded metric format. These performance log events use a structured JSON schema that enables high-cardinality data to be ingested and stored at scale. From this data, CloudWatch creates aggregated metrics at the cluster, node, pod, task, and service level as CloudWatch metrics. The metrics that Container Insights collects are available in CloudWatch automatic dashboards.</p> <p>By combining Container Insights and CloudWatch logs, we are able to provide a foundation for EKS (Elastic Kubernetes Service) Observability. Monitoring EKS for metrics has two categories: the control plane and the Amazon EKS nodes (with Kubernetes objects). The Amazon EKS control plane consists of control plane nodes that run the Kubernetes software, such as etcd and the Kubernetes API server. To read more on the components of an Amazon EKS cluster, please read the service documentation.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#objective","title":"Objective","text":"<ul> <li>Deploys one production grade Amazon EKS cluster.</li> <li>AWS Distro For OpenTelemetry Operator and Collector</li> <li>Logs with AWS for FluentBit and CloudWatch Logs</li> <li>Enables CloudWatch Container Insights.</li> <li>Installs Prometheus Node Exporter for infrastructure metrics.</li> </ul>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#prerequisites","title":"Prerequisites:","text":"<p>Ensure that you have installed the following tools on your machine.</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#deploying","title":"Deploying","text":"<ol> <li>Clone your forked repository</li> </ol> <pre><code>git clone https://github.com/aws-observability/cdk-aws-observability-accelerator.git\n</code></pre> <ol> <li>Install the AWS CDK Toolkit globally on your machine using</li> </ol> <pre><code>npm install -g aws-cdk\n</code></pre> <ol> <li> <p>Install project dependencies by running <code>npm install</code> in the main folder of this cloned repository</p> </li> <li> <p>Once all pre-requisites are set you are ready to deploy the pipeline. Run the following command from the root of this repository to deploy the pipeline stack:</p> </li> </ol> <pre><code>make build\nmake pattern single-new-eks-awsnative-observability deploy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#verify-the-resources","title":"Verify the resources","text":"<p>Run update-kubeconfig command. You should be able to get the command from CDK output message.</p> <pre><code>aws eks update-kubeconfig --name single-new-eks-awsnative-observability-accelerator --region &lt;your region&gt; --role-arn arn:aws:iam::xxxxxxxxx:role/single-new-eks-awsnative-singleneweksawsnativeobs-JN3QM2KMBNCO\n</code></pre> <p>Let\u2019s verify the resources created by steps above.</p> <p><pre><code>kubectl get nodes -o wide\n</code></pre> Output:</p> <pre><code>NAME                                         STATUS   ROLES    AGE    VERSION               INTERNAL-IP    EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME\nip-10-0-104-200.us-west-2.compute.internal   Ready    &lt;none&gt;   2d1h   v1.25.9-eks-0a21954   10.0.104.200   &lt;none&gt;        Amazon Linux 2   5.10.179-168.710.amzn2.x86_64   containerd://1.6.19\n</code></pre> <p>Next, lets verify the namespaces in the cluster:</p> <pre><code>kubectl get ns # Output shows all namespace\n</code></pre> <p>Output:</p> <pre><code>NAME                       STATUS   AGE\namazon-metrics             Active   10m\naws-for-fluent-bit         Active   10m\ncert-manager               Active   10m\ndefault                    Active   16m\nkube-node-lease            Active   16m\nkube-public                Active   16m\nkube-system                Active   16m\nprometheus-node-exporter   Active   10m\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#visualization","title":"Visualization","text":"<p>Navigate to CloudWatch and go to \"Container Insights\".</p> <p>View the Container Map:</p> <p></p> <p>View the Resource List:</p> <p></p> <p>View the Performance Monitoring Dashboard:</p> <p></p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#viewing-logs","title":"Viewing Logs","text":"<p>By default, we deploy a FluentBit daemon set in the cluster to collect worker logs for all namespaces. Logs are collected and exported to Amazon CloudWatch Logs, which enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#using-cloudwatch-logs-insights-to-query-logs","title":"Using CloudWatch Logs Insights to Query Logs","text":"<p>Navigate to CloudWatch, then go to \"Logs Insights\"</p> <p>In the dropdown, select any of the logs that begin with \"/aws/eks/single-new-eks-awsnative-observability-accelerator\" and run a query.</p> <p>Example with \"kubesystem\" log group:</p> <p></p> <p>Then you can view the results of your query:</p> <p></p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-awsnative-observability/#teardown","title":"Teardown","text":"<p>You can teardown the whole CDK stack with the following command:</p> <pre><code>make pattern single-new-eks-awsnative-observability destroy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-cluster/","title":"Single New EKS Cluster Observability Accelerator","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-cluster/#objective","title":"Objective","text":"<p>This pattern deploys one production grade Amazon EKS cluster, without any Observability add-on.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-cluster/#prerequisites","title":"Prerequisites:","text":"<p>Ensure that you have installed the following tools on your machine.</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-cluster/#deploying","title":"Deploying","text":"<ol> <li>Clone your forked repository</li> </ol> <pre><code>git clone https://github.com/aws-observability/cdk-aws-observability-accelerator.git\n</code></pre> <ol> <li>Install the AWS CDK Toolkit globally on your machine using</li> </ol> <pre><code>npm install -g aws-cdk\n</code></pre> <ol> <li> <p>Install project dependencies by running <code>npm install</code> in the main folder of this cloned repository</p> </li> <li> <p>Once all pre-requisites are set you are ready to deploy the pipeline. Run the following command from the root of this repository to deploy the pipeline stack:</p> </li> </ol> <pre><code>make build\nmake pattern single-new-eks-cluster deploy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-cluster/#verify-the-resources","title":"Verify the resources","text":"<p>Run update-kubeconfig command. You should be able to get the command from CDK output message.</p> <pre><code>aws eks update-kubeconfig --name single-new-eks-observability-accelerator --region &lt;your region&gt; --role-arn arn:aws:iam::xxxxxxxxx:role/single-new-eks-observabil-singleneweksobservabilit-5NW0A5AUXVS9\n</code></pre> <p>Let\u2019s verify the resources created by steps above.</p> <p><pre><code>kubectl get nodes -o wide\n</code></pre> Output:</p> <pre><code>NAME                                            STATUS   ROLES    AGE     VERSION               INTERNAL-IP    EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME\nip-10-0-157-151.eu-central-1.compute.internal   Ready    &lt;none&gt;   9m19s   v1.25.9-eks-0a21954   10.0.157.151   &lt;none&gt;        Amazon Linux 2   5.10.179-168.710.amzn2.x86_64   containerd://1.6.19\n</code></pre> <p>Next, lets verify the namespaces in the cluster:</p> <pre><code>kubectl get ns # Output shows all namespace\n</code></pre> <p>Output:</p> <pre><code>NAME                       STATUS   AGE\ncert-manager               Active   7m8s\ndefault                    Active   13m\nexternal-secrets           Active   7m9s\nkube-node-lease            Active   13m\nkube-public                Active   13m\nkube-system                Active   13m\nprometheus-node-exporter   Active   7m9s\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-cluster/#teardown","title":"Teardown","text":"<p>You can teardown the whole CDK stack with the following command:</p> <pre><code>make pattern single-new-eks-cluster destroy\n</code></pre> <p>aws</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/","title":"Single New EKS Graviton Cluster Open Source Observability Accelerator","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#architecture","title":"Architecture","text":"<p>The following figure illustrates the architecture of the pattern we will be deploying for Single EKS Cluster Open Source Observability on Graviton pattern using open source tooling such as AWS Distro for Open Telemetry (ADOT), Amazon Managed Service for Prometheus (AMP), Amazon Managed Grafana :</p> <p></p> <p>Monitoring Amazon Elastic Kubernetes Service (Amazon EKS) for metrics has two categories: the control plane and the Amazon EKS nodes (with Kubernetes objects). The Amazon EKS control plane consists of control plane nodes that run the Kubernetes software, such as etcd and the Kubernetes API server. To read more on the components of an Amazon EKS cluster, please read the service documentation.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#graviton","title":"Graviton","text":"<p>AWS Graviton Processors are designed by AWS to deliver the best price to performance for your cloud workloads running in Amazon EC2.  These processors are ARM chips running on aarch64 architecture. These processors feature key capabilities, such as the AWS Nitro System, that allow you to securely run cloud native applications at scale.</p> <p>Visit our EKS Blueprints docs for a list of supported addons on Graviton.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#objective","title":"Objective","text":"<ul> <li>Deploys one production grade Amazon EKS cluster running on a Graviton3 Processor</li> <li>AWS Distro For OpenTelemetry Operator and Collector for Metrics and Traces</li> <li>Logs with AWS for FluentBit</li> <li>Installs Grafana Operator to add AWS data sources and create Grafana Dashboards to Amazon Managed Grafana.</li> <li>Installs FluxCD to perform GitOps sync of a Git Repo to EKS Cluster. We will use this later for creating Grafana Dashboards and AWS datasources to Amazon Managed Grafana. You can also use your own GitRepo  to sync your own Grafana resources such as Dashboards, Datasources etc. Please check our One observability module - GitOps with Amazon Managed Grafana to learn more about this.</li> <li>Installs External Secrets Operator to retrieve and Sync the Grafana API keys.</li> <li>Amazon Managed Grafana Dashboard and data source</li> <li>Alerts and recording rules with AWS Managed Service for Prometheus</li> </ul>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#prerequisites","title":"Prerequisites:","text":"<p>Ensure that you have installed the following tools on your machine.</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#deploying","title":"Deploying","text":"<ol> <li>Clone your forked repository</li> </ol> <pre><code>git clone https://github.com/aws-observability/cdk-aws-observability-accelerator.git\n</code></pre> <ol> <li>Install the AWS CDK Toolkit globally on your machine using</li> </ol> <pre><code>npm install -g aws-cdk\n</code></pre> <ol> <li>Amazon Managed Grafana workspace: To visualize metrics collected, you need an Amazon Managed Grafana workspace. If you have an existing workspace, create an environment variable as described below. To create a new workspace, visit our supporting example for Grafana</li> </ol> <p>Note</p> <p>For the URL <code>https://g-xyz.grafana-workspace.us-east-1.amazonaws.com</code>, the workspace ID would be <code>g-xyz</code></p> <pre><code>export AWS_REGION=&lt;YOUR AWS REGION&gt;\nexport COA_AMG_WORKSPACE_ID=g-xxx\nexport COA_AMG_ENDPOINT_URL=https://g-xyz.grafana-workspace.us-east-1.amazonaws.com\n</code></pre> <p>Warning</p> <p>Setting up environment variables <code>COA_AMG_ENDPOINT_URL</code> and <code>AWS_REGION</code> is mandatory for successful execution of this pattern.</p> <ol> <li>GRAFANA API KEY: Amazon Managed Grafana provides a control plane API for generating Grafana API keys.</li> </ol> <pre><code>export AMG_API_KEY=$(aws grafana create-workspace-api-key \\\n--key-name \"grafana-operator-key\" \\\n--key-role \"ADMIN\" \\\n--seconds-to-live 432000 \\\n--workspace-id $COA_AMG_WORKSPACE_ID \\\n--query key \\\n--output text)\n</code></pre> <ol> <li>AWS Secrets Manager for GRAFANA API KEY: Update the Grafana API key secret in AWS Secrets using the above new Grafana API key. This will be referenced by Grafana Operator deployment of our solution to access Amazon Managed Grafana from Amazon EKS Cluster</li> </ol> <pre><code>aws secretsmanager create-secret \\\n--name grafana-api-key \\\n--description \"API Key of your Grafana Instance\" \\\n--secret-string \"${AMG_API_KEY}\" \\\n--region $AWS_REGION \\\n--query ARN \\\n--output text\n</code></pre> <ol> <li> <p>Install project dependencies by running <code>npm install</code> in the main folder of this cloned repository. </p> </li> <li> <p>The actual settings for dashboard urls are expected to be specified in the CDK context. Generically it is inside the cdk.json file of the current directory or in <code>~/.cdk.json</code> in your home directory. </p> </li> </ol> <p>Example settings: Update the context in <code>cdk.json</code> file located in <code>cdk-eks-blueprints-patterns</code> directory</p> <pre><code>    \"context\": {\n        \"cluster.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/cluster.json\",\n        \"kubelet.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/kubelet.json\",\n        \"namespaceworkloads.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/namespace-workloads.json\",\n        \"nodeexporter.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/nodeexporter-nodes.json\",\n        \"nodes.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/nodes.json\",\n        \"workloads.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/workloads.json\",\n        \"apiserver.basic.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-basic.json\",\n        \"apiserver.advanced.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-advanced.json\",\n        \"apiserver.troubleshooting.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-troubleshooting.json\",\n      }\n</code></pre> <ol> <li>Once all pre-requisites are set you are ready to deploy the pipeline. Run the following command from the root of this repository to deploy the pipeline stack:</li> </ol> <pre><code>make build\nmake pattern single-new-eks-graviton-opensource-observability deploy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#verify-the-resources","title":"Verify the resources","text":"<p>Run update-kubeconfig command. You should be able to get the command from CDK output message.</p> <pre><code>aws eks update-kubeconfig --name single-new-eks-graviton-opensource-observability-accelerator --region &lt;your region&gt; --role-arn arn:aws:iam::xxxxxxxxx:role/single-new-eks-gravitonop-singleneweksgravitonopens-82N8N3BMJYYI\n</code></pre> <p>Let\u2019s verify the resources created by steps above.</p> <p><pre><code>kubectl get nodes -o wide\n</code></pre> Output:</p> <pre><code>NAME                                         STATUS   ROLES    AGE    VERSION               INTERNAL-IP    EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME\nip-10-0-104-200.us-west-2.compute.internal   Ready    &lt;none&gt;   2d1h   v1.27.1-eks-2f008fe   10.0.104.200   &lt;none&gt;        Amazon Linux 2   5.10.179-168.710.amzn2.aarch64   containerd://1.6.19\n</code></pre> <p>Next, lets verify the namespaces in the cluster:</p> <pre><code>kubectl get ns # Output shows all namespace\n</code></pre> <p>Output:</p> <pre><code>NAME                            STATUS   AGE\ncert-manager                    Active   2d1h\ndefault                         Active   2d1h\nexternal-secrets                Active   2d1h\nflux-system                     Active   2d1h\ngrafana-operator                Active   2d1h\nkube-node-lease                 Active   2d1h\nkube-public                     Active   2d1h\nkube-system                     Active   2d1h\nopentelemetry-operator-system   Active   2d1h\nprometheus-node-exporter        Active   2d1h\n</code></pre> <p>Next, lets verify all resources of <code>grafana-operator</code> namespace:</p> <pre><code>kubectl get all --namespace=grafana-operator\n</code></pre> <p>Output:</p> <pre><code>NAME                                    READY   STATUS    RESTARTS   AGE\npod/grafana-operator-866d4446bb-g5srl   1/1     Running   0          2d1h\n\nNAME                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE\nservice/grafana-operator-metrics-service   ClusterIP   172.20.223.125   &lt;none&gt;        9090/TCP   2d1h\n\nNAME                               READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/grafana-operator   1/1     1            1           2d1h\n\nNAME                                          DESIRED   CURRENT   READY   AGE\nreplicaset.apps/grafana-operator-866d4446bb   1         1         1       2d1h\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#visualization","title":"Visualization","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#1-grafana-dashboards","title":"1. Grafana dashboards","text":"<p>Login to your Grafana workspace and navigate to the Dashboards panel. You should see a list of dashboards under the <code>Observability Accelerator Dashboards</code></p> <p></p> <p>Open the <code>Node Exporter</code> dashboard and you should be able to view its visualization as shown below :</p> <p></p> <p>Open the <code>Kubelet</code> dashboard and you should be able to view its visualization as shown below :</p> <p></p> <p>From the cluster to view all dashboards as Kubernetes objects, run:</p> <pre><code>kubectl get grafanadashboards -A\n</code></pre> <pre><code>NAMESPACE          NAME                                   AGE\ngrafana-operator   cluster-grafanadashboard               138m\ngrafana-operator   java-grafanadashboard                  143m\ngrafana-operator   kubelet-grafanadashboard               13h\ngrafana-operator   namespace-workloads-grafanadashboard   13h\ngrafana-operator   nginx-grafanadashboard                 134m\ngrafana-operator   node-exporter-grafanadashboard         13h\ngrafana-operator   nodes-grafanadashboard                 13h\ngrafana-operator   workloads-grafanadashboard             13h\n</code></pre> <p>You can inspect more details per dashboard using this command</p> <pre><code>kubectl describe grafanadashboards cluster-grafanadashboard -n grafana-operator\n</code></pre> <p>Grafana Operator and Flux always work together to synchronize your dashboards with Git. If you delete your dashboards by accident, they will be re-provisioned automatically.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#viewing-logs","title":"Viewing Logs","text":"<p>By default, we deploy a FluentBit daemon set in the cluster to collect worker logs for all namespaces. Logs are collected and exported to Amazon CloudWatch Logs, which enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#using-cloudwatch-logs-as-data-source-in-grafana","title":"Using CloudWatch Logs as data source in Grafana","text":"<p>Follow the documentation to enable Amazon CloudWatch as a data source. Make sure to provide permissions.</p> <p>All logs are delivered in the following CloudWatch Log groups naming pattern: <code>/aws/eks/single-new-eks-opensource-observability-accelerator</code>. Log streams follow <code>{container-name}.{pod-name}</code>. In Grafana, querying and analyzing logs is done with CloudWatch Logs Insights</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#example-adot-collector-logs","title":"Example - ADOT collector logs","text":"<p>Select one or many log groups and run the following query. The example below, queries AWS Distro for OpenTelemetry (ADOT) logs</p> <pre><code>fields @timestamp, log\n| order @timestamp desc\n| limit 100\n</code></pre> <p></p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#example-using-time-series-visualizations","title":"Example - Using time series visualizations","text":"<p>CloudWatch Logs syntax provide powerful functions to extract data from your logs. The <code>stats()</code> function allows you to calculate aggregate statistics with log field values. This is useful to have visualization on non-metric data from your applications.</p> <p>In the example below, we use the following query to graph the number of metrics collected by the ADOT collector</p> <pre><code>fields @timestamp, log\n| parse log /\"#metrics\": (?&lt;metrics_count&gt;\\d+)}/\n| stats avg(metrics_count) by bin(5m)\n| limit 100\n</code></pre> <p>Tip</p> <p>You can add logs in your dashboards with logs panel types or time series depending on your query results type.</p> <p></p> <p>Warning</p> <p>Querying CloudWatch logs will incur costs per GB scanned. Use small time windows and limits in your queries. Checkout the CloudWatch pricing page for more infos.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-graviton-opensource-observability/#1-grafana-dashboards-missing-or-grafana-api-key-expired","title":"1. Grafana dashboards missing or Grafana API key expired","text":"<p>In case you don't see the grafana dashboards in your Amazon Managed Grafana console, check on the logs on your grafana operator pod using the below command :</p> <pre><code>kubectl get pods -n grafana-operator\n</code></pre> <p>Output:</p> <pre><code>NAME                                READY   STATUS    RESTARTS   AGE\ngrafana-operator-866d4446bb-nqq5c   1/1     Running   0          3h17m\n</code></pre> <pre><code>kubectl logs grafana-operator-866d4446bb-nqq5c -n grafana-operator\n</code></pre> <p>Output:</p> <pre><code>1.6857285045556655e+09  ERROR   error reconciling datasource    {\"controller\": \"grafanadatasource\", \"controllerGroup\": \"grafana.integreatly.org\", \"controllerKind\": \"GrafanaDatasource\", \"GrafanaDatasource\": {\"name\":\"grafanadatasource-sample-amp\",\"namespace\":\"grafana-operator\"}, \"namespace\": \"grafana-operator\", \"name\": \"grafanadatasource-sample-amp\", \"reconcileID\": \"72cfd60c-a255-44a1-bfbd-88b0cbc4f90c\", \"datasource\": \"grafanadatasource-sample-amp\", \"grafana\": \"external-grafana\", \"error\": \"status: 401, body: {\\\"message\\\":\\\"Expired API key\\\"}\\n\"}\ngithub.com/grafana-operator/grafana-operator/controllers.(*GrafanaDatasourceReconciler).Reconcile\n</code></pre> <p>If you observe, the the above <code>grafana-api-key error</code> in the logs, your grafana API key is expired. Please use the operational procedure to update your <code>grafana-api-key</code> :</p> <ul> <li>First, lets create a new Grafana API key.</li> </ul> <pre><code>export GO_AMG_API_KEY=$(aws grafana create-workspace-api-key \\\n--key-name \"grafana-operator-key-new\" \\\n--key-role \"ADMIN\" \\\n--seconds-to-live 432000 \\\n--workspace-id $COA_AMG_WORKSPACE_ID \\\n--query key \\\n--output text)\n</code></pre> <ul> <li>Finally, update the Grafana API key secret in AWS Secrets Manager using the above new Grafana API key:</li> </ul> <pre><code>export API_KEY_SECRET_NAME=\"grafana-api-key\"\naws secretsmanager update-secret \\\n--secret-id $API_KEY_SECRET_NAME \\\n--secret-string \"${AMG_API_KEY}\" \\\n--region $AWS_REGION\n</code></pre> <ul> <li>If the issue persists, you can force the synchronization by deleting the <code>externalsecret</code> Kubernetes object.</li> </ul> <pre><code>kubectl delete externalsecret/external-secrets-sm -n grafana-operator\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/","title":"Single New EKS Cluster AWS Mixed Observability Accelerator","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#architecture","title":"Architecture","text":"<p>The following figure illustrates the architecture of the pattern we will be deploying for Single EKS Cluster Mixed Observability pattern using AWS native tools such as CloudWatch and X-Ray and Open Source tools such as Amazon Distro for OpenTelmetry(ADOT) and Prometheus Node Exporter.</p> <p></p> <p>This example makes use of CloudWatch as a metric and log aggregation layer while X-Ray is used as a trace-aggregation layer. In order to collect the metrics and traces we use the Open Source ADOT collector. Fluent Bit is used to export the logs to CloudWatch Logs.</p> <p>In this architecture AWS X-Ray provides a complete view of requests as they travel through your application and filters visual data across payloads, functions, traces, services, and APIs. X-Ray also allows you to perform analytics to gain powerful insights about your distributed trace data.</p> <p>Utilizing CloudWatch and X-Ray as an aggregation layer allows for a fully-managed scalable telemetry backend. In this example we get those benefits while still having the flexibility and rapid development of the Open Source collection tools.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#objective","title":"Objective","text":"<ul> <li>Deploys one production grade Amazon EKS cluster.</li> <li>AWS Distro For OpenTelemetry Operator and Collector configured to collect metrics and traces.</li> <li>Logs with AWS for FluentBit and CloudWatch Logs</li> <li>Aggregate Metrics in CloudWatch</li> <li>Aggregate Traces in X-Ray</li> </ul> <p>Ensure that you have installed the following tools on your machine.</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#deploying","title":"Deploying","text":"<ol> <li>Clone your forked repository</li> </ol> <pre><code>git clone https://github.com/aws-observability/cdk-aws-observability-accelerator.git\n</code></pre> <ol> <li>Install the AWS CDK Toolkit globally on your machine using</li> </ol> <pre><code>npm install -g aws-cdk\n</code></pre> <ol> <li> <p>Install project dependencies by running <code>npm install</code> in the main folder of this cloned repository</p> </li> <li> <p>Once all pre-requisites are set you are ready to deploy the pipeline. Run the following command from the root of this repository to deploy the pipeline stack:</p> </li> </ol> <pre><code>make build\nmake pattern single-new-eks-mixed-observability deploy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#verify-the-resources","title":"Verify the resources","text":"<p>Run update-kubeconfig command. You should be able to get the command from CDK output message.</p> <pre><code>aws eks update-kubeconfig --name single-new-eks-mixed-observability-accelerator --region &lt;your region&gt; --role-arn arn:aws:iam::xxxxxxxxx:role/single-new-eks-opensource-singleneweksopensourceob-82N8N3BMJYYI\n</code></pre> <p>Let\u2019s verify the resources created by steps above.</p> <pre><code>kubectl get nodes -o wide\n</code></pre> <p>Output:</p> <pre><code>NAME                                         STATUS   ROLES    AGE    VERSION               INTERNAL-IP    EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME\nip-10-0-144-134.us-west-1.compute.internal   Ready    &lt;none&gt;   143m   v1.25.9-eks-0a21954   10.0.144.134   &lt;none&gt;        Amazon Linux 2   5.10.179-168.710.amzn2.x86_64   containerd://1.6.19\n</code></pre> <p>Next, lets verify the namespaces in the cluster:</p> <pre><code>kubectl get ns # Output shows all namespace\n</code></pre> <p>Output:</p> <pre><code>NAME                            STATUS   AGE\naws-for-fluent-bit              Active   142m\ncert-manager                    Active   142m\ndefault                         Active   148m\nexternal-secrets                Active   142m\nkube-node-lease                 Active   149m\nkube-public                     Active   149m\nkube-system                     Active   149m\nopentelemetry-operator-system   Active   142m\nprometheus-node-exporter        Active   142m\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#visualization","title":"Visualization","text":"<p>Navigate to CloudWatch and go to Metrics -&gt; All Metrics.</p> <p>Select the metrics in the ContainerInsights/Prometheus Namespace:</p> <p></p> <p>View the graph of the selected metrics:</p> <p></p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#viewing-logs","title":"Viewing Logs","text":"<p>By default, we deploy a FluentBit daemon set in the cluster to collect worker logs for all namespaces. Logs are collected and exported to Amazon CloudWatch Logs, which enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#using-cloudwatch-logs-insights-to-query-logs","title":"Using CloudWatch Logs Insights to Query Logs","text":"<p>Navigate to CloudWatch, then go to \"Logs Insights\"</p> <p>In the dropdown, select any of the logs that begin with \"/aws/eks/single-new-eks-mixed-observability-accelerator\" and run a query.</p> <p>Example with \"kubesystem\" log group:</p> <p></p> <p>Then you can view the results of your query:</p> <p></p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-mixed-observability/#teardown","title":"Teardown","text":"<p>You can teardown the whole CDK stack with the following command:</p> <pre><code>make pattern single-new-eks-mixed-observability destroy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/","title":"Single New EKS Cluster Open Source Observability Accelerator","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#architecture","title":"Architecture","text":"<p>The following figure illustrates the architecture of the pattern we will be deploying for Single EKS Cluster Open Source Observability pattern using open source tooling such as AWS Distro for Open Telemetry (ADOT), Amazon Managed Service for Prometheus (AMP), Amazon Managed Grafana :</p> <p></p> <p>Monitoring Amazon Elastic Kubernetes Service (Amazon EKS) for metrics has two categories: the control plane and the Amazon EKS nodes (with Kubernetes objects). The Amazon EKS control plane consists of control plane nodes that run the Kubernetes software, such as etcd and the Kubernetes API server. To read more on the components of an Amazon EKS cluster, please read the service documentation.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#objective","title":"Objective","text":"<ul> <li>Deploys one production grade Amazon EKS cluster.</li> <li>AWS Distro For OpenTelemetry Operator and Collector for Metrics and Traces</li> <li>Logs with AWS for FluentBit</li> <li>Installs Grafana Operator to add AWS data sources and create Grafana Dashboards to Amazon Managed Grafana.</li> <li>Installs FluxCD to perform GitOps sync of a Git Repo to EKS Cluster. We will use this later for creating Grafana Dashboards and AWS datasources to Amazon Managed Grafana. You can also use your own GitRepo  to sync your own Grafana resources such as Dashboards, Datasources etc. Please check our One observability module - GitOps with Amazon Managed Grafana to learn more about this.</li> <li>Installs External Secrets Operator to retrieve and Sync the Grafana API keys.</li> <li>Amazon Managed Grafana Dashboard and data source</li> <li>Alerts and recording rules with AWS Managed Service for Prometheus</li> </ul>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#prerequisites","title":"Prerequisites:","text":"<p>Ensure that you have installed the following tools on your machine.</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>cdk</li> <li>npm</li> </ol>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#deploying","title":"Deploying","text":"<ol> <li>Clone your forked repository</li> </ol> <pre><code>git clone https://github.com/aws-observability/cdk-aws-observability-accelerator.git\n</code></pre> <ol> <li>Install the AWS CDK Toolkit globally on your machine using</li> </ol> <pre><code>npm install -g aws-cdk\n</code></pre> <ol> <li>Amazon Managed Grafana workspace: To visualize metrics collected, you need an Amazon Managed Grafana workspace. If you have an existing workspace, create an environment variable as described below. To create a new workspace, visit our supporting example for Grafana</li> </ol> <p>Note</p> <p>For the URL <code>https://g-xyz.grafana-workspace.us-east-1.amazonaws.com</code>, the workspace ID would be <code>g-xyz</code></p> <pre><code>export AWS_REGION=&lt;YOUR AWS REGION&gt;\nexport COA_AMG_WORKSPACE_ID=g-xxx\nexport COA_AMG_ENDPOINT_URL=https://g-xyz.grafana-workspace.us-east-1.amazonaws.com\n</code></pre> <p>Warning</p> <p>Setting up environment variables <code>COA_AMG_ENDPOINT_URL</code> and <code>AWS_REGION</code> is mandatory for successful execution of this pattern.</p> <ol> <li>GRAFANA API KEY: Amazon Managed Grafana provides a control plane API for generating Grafana API keys.</li> </ol> <pre><code>export AMG_API_KEY=$(aws grafana create-workspace-api-key \\\n--key-name \"grafana-operator-key\" \\\n--key-role \"ADMIN\" \\\n--seconds-to-live 432000 \\\n--workspace-id $COA_AMG_WORKSPACE_ID \\\n--query key \\\n--output text)\n</code></pre> <ol> <li>AWS SSM Parameter Store for GRAFANA API KEY: Update the Grafana API key secret in AWS SSM Parameter Store using the above new Grafana API key. This will be referenced by Grafana Operator deployment of our solution to access Amazon Managed Grafana from Amazon EKS Cluster</li> </ol> <pre><code>aws ssm put-parameter --name \"/cdk-accelerator/grafana-api-key\" \\\n--type \"SecureString\" \\\n--value $AMG_API_KEY \\\n--region $AWS_REGION\n</code></pre> <ol> <li> <p>Install project dependencies by running <code>npm install</code> in the main folder of this cloned repository. </p> </li> <li> <p>The actual settings for dashboard urls are expected to be specified in the CDK context. Generically it is inside the cdk.json file of the current directory or in <code>~/.cdk.json</code> in your home directory. </p> </li> </ol> <p>Example settings: Update the context in <code>cdk.json</code> file located in <code>cdk-eks-blueprints-patterns</code> directory</p> <pre><code>    \"context\": {\n        \"cluster.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/cluster.json\",\n        \"kubelet.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/kubelet.json\",\n        \"namespaceworkloads.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/namespace-workloads.json\",\n        \"nodeexporter.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/nodeexporter-nodes.json\",\n        \"nodes.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/nodes.json\",\n        \"workloads.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/workloads.json\",\n        \"apiserver.basic.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-basic.json\",\n        \"apiserver.advanced.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-advanced.json\",\n        \"apiserver.troubleshooting.dashboard.url\": \"https://raw.githubusercontent.com/aws-observability/aws-observability-accelerator/main/artifacts/grafana-dashboards/eks/infrastructure/apiserver-troubleshooting.json\",\n      }\n</code></pre> <ol> <li>Once all pre-requisites are set you are ready to deploy the pipeline. Run the following command from the root of this repository to deploy the pipeline stack:</li> </ol> <pre><code>make build\nmake pattern single-new-eks-opensource-observability deploy\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#verify-the-resources","title":"Verify the resources","text":"<p>Run update-kubeconfig command. You should be able to get the command from CDK output message.</p> <pre><code>aws eks update-kubeconfig --name single-new-eks-opensource-observability-accelerator --region &lt;your region&gt; --role-arn arn:aws:iam::xxxxxxxxx:role/single-new-eks-opensource-singleneweksopensourceob-82N8N3BMJYYI\n</code></pre> <p>Let\u2019s verify the resources created by steps above.</p> <p><pre><code>kubectl get nodes -o wide\n</code></pre> Output:</p> <pre><code>NAME                                         STATUS   ROLES    AGE    VERSION               INTERNAL-IP    EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME\nip-10-0-104-200.us-west-2.compute.internal   Ready    &lt;none&gt;   2d1h   v1.25.9-eks-0a21954   10.0.104.200   &lt;none&gt;        Amazon Linux 2   5.10.179-168.710.amzn2.x86_64   containerd://1.6.19\n</code></pre> <p>Next, lets verify the namespaces in the cluster:</p> <pre><code>kubectl get ns # Output shows all namespace\n</code></pre> <p>Output:</p> <pre><code>NAME                            STATUS   AGE\ncert-manager                    Active   2d1h\ndefault                         Active   2d1h\nexternal-secrets                Active   2d1h\nflux-system                     Active   2d1h\ngrafana-operator                Active   2d1h\nkube-node-lease                 Active   2d1h\nkube-public                     Active   2d1h\nkube-system                     Active   2d1h\nopentelemetry-operator-system   Active   2d1h\nprometheus-node-exporter        Active   2d1h\n</code></pre> <p>Next, lets verify all resources of <code>grafana-operator</code> namespace:</p> <pre><code>kubectl get all --namespace=grafana-operator\n</code></pre> <p>Output:</p> <pre><code>NAME                                    READY   STATUS    RESTARTS   AGE\npod/grafana-operator-866d4446bb-g5srl   1/1     Running   0          2d1h\n\nNAME                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE\nservice/grafana-operator-metrics-service   ClusterIP   172.20.223.125   &lt;none&gt;        9090/TCP   2d1h\n\nNAME                               READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/grafana-operator   1/1     1            1           2d1h\n\nNAME                                          DESIRED   CURRENT   READY   AGE\nreplicaset.apps/grafana-operator-866d4446bb   1         1         1       2d1h\n</code></pre>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#visualization","title":"Visualization","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#1-grafana-dashboards","title":"1. Grafana dashboards","text":"<p>Login to your Grafana workspace and navigate to the Dashboards panel. You should see a list of dashboards under the <code>Observability Accelerator Dashboards</code></p> <p></p> <p>Open the <code>Node Exporter</code> dashboard and you should be able to view its visualization as shown below :</p> <p></p> <p>Open the <code>Kubelet</code> dashboard and you should be able to view its visualization as shown below :</p> <p></p> <p>From the cluster to view all dashboards as Kubernetes objects, run:</p> <pre><code>kubectl get grafanadashboards -A\n</code></pre> <pre><code>NAMESPACE          NAME                                   AGE\ngrafana-operator   cluster-grafanadashboard               138m\ngrafana-operator   java-grafanadashboard                  143m\ngrafana-operator   kubelet-grafanadashboard               13h\ngrafana-operator   namespace-workloads-grafanadashboard   13h\ngrafana-operator   nginx-grafanadashboard                 134m\ngrafana-operator   node-exporter-grafanadashboard         13h\ngrafana-operator   nodes-grafanadashboard                 13h\ngrafana-operator   workloads-grafanadashboard             13h\n</code></pre> <p>You can inspect more details per dashboard using this command</p> <pre><code>kubectl describe grafanadashboards cluster-grafanadashboard -n grafana-operator\n</code></pre> <p>Grafana Operator and Flux always work together to synchronize your dashboards with Git. If you delete your dashboards by accident, they will be re-provisioned automatically.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#viewing-logs","title":"Viewing Logs","text":"<p>By default, we deploy a FluentBit daemon set in the cluster to collect worker logs for all namespaces. Logs are collected and exported to Amazon CloudWatch Logs, which enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#using-cloudwatch-logs-as-data-source-in-grafana","title":"Using CloudWatch Logs as data source in Grafana","text":"<p>Follow the documentation to enable Amazon CloudWatch as a data source. Make sure to provide permissions.</p> <p>All logs are delivered in the following CloudWatch Log groups naming pattern: <code>/aws/eks/single-new-eks-opensource-observability-accelerator</code>. Log streams follow <code>{container-name}.{pod-name}</code>. In Grafana, querying and analyzing logs is done with CloudWatch Logs Insights</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#example-adot-collector-logs","title":"Example - ADOT collector logs","text":"<p>Select one or many log groups and run the following query. The example below, queries AWS Distro for OpenTelemetry (ADOT) logs</p> <pre><code>fields @timestamp, log\n| order @timestamp desc\n| limit 100\n</code></pre> <p></p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#example-using-time-series-visualizations","title":"Example - Using time series visualizations","text":"<p>CloudWatch Logs syntax provide powerful functions to extract data from your logs. The <code>stats()</code> function allows you to calculate aggregate statistics with log field values. This is useful to have visualization on non-metric data from your applications.</p> <p>In the example below, we use the following query to graph the number of metrics collected by the ADOT collector</p> <pre><code>fields @timestamp, log\n| parse log /\"#metrics\": (?&lt;metrics_count&gt;\\d+)}/\n| stats avg(metrics_count) by bin(5m)\n| limit 100\n</code></pre> <p>Tip</p> <p>You can add logs in your dashboards with logs panel types or time series depending on your query results type.</p> <p></p> <p>Warning</p> <p>Querying CloudWatch logs will incur costs per GB scanned. Use small time windows and limits in your queries. Checkout the CloudWatch pricing page for more infos.</p>"},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"patterns/single-new-eks-observability-accelerators/single-new-eks-opensource-observability/#1-grafana-dashboards-missing-or-grafana-api-key-expired","title":"1. Grafana dashboards missing or Grafana API key expired","text":"<p>In case you don't see the grafana dashboards in your Amazon Managed Grafana console, check on the logs on your grafana operator pod using the below command :</p> <pre><code>kubectl get pods -n grafana-operator\n</code></pre> <p>Output:</p> <pre><code>NAME                                READY   STATUS    RESTARTS   AGE\ngrafana-operator-866d4446bb-nqq5c   1/1     Running   0          3h17m\n</code></pre> <pre><code>kubectl logs grafana-operator-866d4446bb-nqq5c -n grafana-operator\n</code></pre> <p>Output:</p> <pre><code>1.6857285045556655e+09  ERROR   error reconciling datasource    {\"controller\": \"grafanadatasource\", \"controllerGroup\": \"grafana.integreatly.org\", \"controllerKind\": \"GrafanaDatasource\", \"GrafanaDatasource\": {\"name\":\"grafanadatasource-sample-amp\",\"namespace\":\"grafana-operator\"}, \"namespace\": \"grafana-operator\", \"name\": \"grafanadatasource-sample-amp\", \"reconcileID\": \"72cfd60c-a255-44a1-bfbd-88b0cbc4f90c\", \"datasource\": \"grafanadatasource-sample-amp\", \"grafana\": \"external-grafana\", \"error\": \"status: 401, body: {\\\"message\\\":\\\"Expired API key\\\"}\\n\"}\ngithub.com/grafana-operator/grafana-operator/controllers.(*GrafanaDatasourceReconciler).Reconcile\n</code></pre> <p>If you observe, the the above <code>grafana-api-key error</code> in the logs, your grafana API key is expired. Please use the operational procedure to update your <code>grafana-api-key</code> :</p> <ul> <li>First, lets create a new Grafana API key.</li> </ul> <pre><code>export GO_AMG_API_KEY=$(aws grafana create-workspace-api-key \\\n--key-name \"grafana-operator-key-new\" \\\n--key-role \"ADMIN\" \\\n--seconds-to-live 432000 \\\n--workspace-id $COA_AMG_WORKSPACE_ID \\\n--query key \\\n--output text)\n</code></pre> <ul> <li>Finally, update the Grafana API key secret in AWS SSM Parameter Store using the above new Grafana API key:</li> </ul> <pre><code>export API_KEY_SECRET_NAME=\"grafana-api-key\"\naws ssm put-parameter --name \"/cdk-accelerator/grafana-api-key\" \\\n--type \"SecureString\" \\\n--value $AMG_API_KEY \\\n--region $AWS_REGION \\\n--overwrite\n</code></pre> <ul> <li>If the issue persists, you can force the synchronization by deleting the <code>externalsecret</code> Kubernetes object.</li> </ul> <pre><code>kubectl delete externalsecret/external-secrets-sm -n grafana-operator\n</code></pre>"}]}